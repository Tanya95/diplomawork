{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pickle as cPickle\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "%pylab inline \n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "from PIL import Image\n",
    "import PIL.ImageOps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirPath = 'ASL/signs/'\n",
    "import os\n",
    "signs = ''\n",
    "for f in os.listdir(dirPath):\n",
    "    fname = dirPath+f\n",
    "    base=os.path.basename(fname)\n",
    "    sign = os.path.splitext(base)[0]\n",
    "    signs += sign\n",
    "    pass\n",
    "signs = sorted(signs)\n",
    "print(signs)\n",
    "print(len(signs))\n",
    "signs.index('z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 250)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3071ed5c18>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOCzMLInDwsySOCzMLInDwsyS/D9k4+WSLrLywgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3071fb53c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = Image.open('ASL/signs/z.jpg')\n",
    "im = PIL.ImageOps.invert(im)\n",
    "im = im.convert('1')\n",
    "im.save('result.png')\n",
    "(width, height) = im.size\n",
    "im.size\n",
    "print(im.size)\n",
    "px=im.getpixel((60, 95))\n",
    "print(px)\n",
    "\n",
    "imgB = np.asarray(im)\n",
    "imgB\n",
    "pl.imshow(imgB,cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    traning_data - массив из 50000 тренировочных примеров, \n",
    "    0 - элемент содержит массив массивов бит изображений\n",
    "    1 - соответствующий картинке номер\n",
    "    validation_data и test_data аналогичные, но содержат \n",
    "    по 10000 значений\n",
    "    '''\n",
    "    f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "    training_data, validation_data, test_data = cPickle.load(f,encoding='latin1')\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_wrapper():\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "    training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "    #print(training_inputs[0])\n",
    "    #print(training_results[0])\n",
    "    training_data = zip(training_inputs, training_results)\n",
    "    #print(training_data[0])\n",
    "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "    validation_data = zip(validation_inputs, va_d[1])\n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "    test_zipped = zip(test_inputs, te_d[1])\n",
    "    # print(training_data, validation_data, test_zipped)\n",
    "    return (training_data, validation_data,test_zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training, validation, test=load_data_wrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trd = list(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(len(trd))\n",
    "#print(trd[1:10][1])\n",
    "#nerobit = trd[0:2]\n",
    "#print(len(nerobit))\n",
    "#print(nerobit[0][0])\n",
    "\n",
    "#mini_batches =[trd[0:10]\n",
    "#                for k in range(0, n, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorized_result(j,size):\n",
    "    e = np.zeros((10, size))\n",
    "    print('size',size)\n",
    "    cnt=0\n",
    "    for i in j:\n",
    "        print('i:',i,'j:',j)\n",
    "        e[i][cnt] = 1.0\n",
    "        cnt+=1\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, validation, test = load_data()\n",
    "Xdisplay = np.reshape(training[0][1],(28,28))\n",
    "y = vectorized_result(training[1][0:5],5)\n",
    "print(y)\n",
    "#print(training[1][0:10])\n",
    "pl.imshow(Xdisplay,cmap='Greys')\n",
    "pl.xlabel(('Number %d' % training[1][1]))  \n",
    "X = np.float32(training[0][0:5])#, dtype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.T.shape)\n",
    "# b = np.dot(X.T,5)\n",
    "# for ln in b:\n",
    "#     for el in ln:\n",
    "#         if el >0:\n",
    "#             print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testInput = np.arange(-6,6,0.01)\n",
    "#plot(testInput, sigmoid(testInput), linewidth= 2)\n",
    "#grid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#net.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 28*28\n",
    "        self.outputLayerSize = 10\n",
    "        self.hiddenLayerSize = 20\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        # print (self.W1.shape,self.W2.shape)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propogate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        # print ('z2',self.z2)\n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)\n",
    "        # print (J)\n",
    "        return J\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        # print('YHat',self.yHat)\n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "        # print('delta',delta3)\n",
    "        # print('delta.shape',delta3.shape)\n",
    "        # print('a2',self.a2.shape)\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        # print('Djdw',dJdW2)\n",
    "        \n",
    "        delta2 = np.float32(np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2))\n",
    "        # print('delta2', delta2)\n",
    "        # print('delta2.shape:',delta2.shape)\n",
    "        # print('X.T.shape:',X.T.shape)\n",
    "\n",
    "        dJdW1 = np.dot(X.T, delta2)\n",
    "#         for ln in dJdW1:\n",
    "#             for el in ln:\n",
    "#                 if el >0:\n",
    "#                     print(el)\n",
    "        # dJdW1 = np.dot(2, delta2)\n",
    "        # dJdW1 = np.dot(X.T, 2)\n",
    "        # print (dJdW1,dJdW2)\n",
    "        # print('sigmoid.z2',self.sigmoidPrime(self.z2))\n",
    "        # print('W2.T',self.W2.T.shape)\n",
    "        # print('delta2',delta2.shape)\n",
    "        # print('X.T',X.T.shape)\n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 unrolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single paramater vector.\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize * self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n",
    "        \n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost1 = NN.costFunction(X,y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dJdW1, dJdW2 = NN.costFunctionPrime(X,y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dJdW1',dJdW1,'dJdW2',dJdW2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costarr=[]\n",
    "for i in range(0,10):\n",
    "    cost = NN.costFunction(X,y.T)\n",
    "    costarr.append(cost)\n",
    "    dJdW1, dJdW2 = NN.costFunctionPrime(X,y.T)\n",
    "    scalar = 3\n",
    "    NN.W1 = NN.W1 - scalar*dJdW1\n",
    "    NN.W2 = NN.W2 - scalar*dJdW2\n",
    "print(costarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result=NN.forward(X)\n",
    "result=np.around(result, decimals = 2)\n",
    "print(result)\n",
    "# print(y.T)\n",
    "yarr=training[1][0:5]\n",
    "res=[np.argmax(i) for i in  result]\n",
    "print(res)\n",
    "print(yarr)\n",
    "# print(list(zip(res,yarr)))\n",
    "sum(int(x == y) for (x, y) in list(zip(res,yarr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(costarr)\n",
    "grid(1)\n",
    "xlabel('Iterations')\n",
    "ylabel('Cost')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
